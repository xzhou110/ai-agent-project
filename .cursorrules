üß† AI Self-Evolving Guidelines

IMPORTANT: Instructions in all sections should only be intentionally updated and preserved carefully.




üìã Instructions

During interactions, document reusable insights (e.g., versions of libraries, models, fixes to mistakes, corrections received) in the LESSONS LEARNED section. Use this file actively as a workspace (Scratchpad) to plan, track, and reflect clearly on tasks.




üìå Task Planning and Progress

When starting a new task:
[X] Clearly explain goal and core requirements
[ ] Subdivide tasks into manageable subtasks
[ ] Track subtasks clearly (mark completed with [X])
[ ] Regularly update and reflect after milestones
[ ] Document barriers encountered and successful strategies




üõ†Ô∏è Tools

Note all tools/scripts used clearly, including purpose, commands, and concise examples:

Search Engine Tool:
‚Ä¢ Location: utils/search_engine.py
‚Ä¢ Purpose: Search the internet via DuckDuckGo with retry logic and fallback
‚Ä¢ Functions:
  - search_internet(query, max_results=10, max_retries=3)
  - search_with_fallback(query, max_results=10, max_retries=3)
‚Ä¢ Example:
  ```python
  from utils.search_engine import search_internet
  results = search_internet("fashion news", max_results=5)
  for r in results:
      print(f"{r['title']} - {r['url']}")
  ```
‚Ä¢ Usage: `py utils/demo_search.py "query" --max-results=5`
‚Ä¢ Dependencies: requests, beautifulsoup4

Web Scraper Tool:
‚Ä¢ Location: utils/web_scraper.py
‚Ä¢ Purpose: Extract content from websites with anti-blocking measures
‚Ä¢ Functions:
  - WebScraper class with methods for different content types
  - scrape_webpage(url, selectors, delay_range, max_retries)
  - scrape_article(url, delay_range, max_retries)
  - scrape_table(url, table_selector, delay_range, max_retries)
  - search_webpage(url, search_terms, context_size, delay_range, max_retries)
‚Ä¢ Example:
  ```python
  from utils.web_scraper import scrape_article
  article = scrape_article("https://example.com/blog/post")
  print(f"Title: {article['title']}")
  print(f"Content: {article['text'][:150]}...")
  ```
‚Ä¢ Usage: `py utils/demo_web_scraper.py --url https://example.com --type article`
‚Ä¢ Dependencies: requests, beautifulsoup4

NOTE: For complete documentation of each tool, refer to the README.md file in the respective utility folder. This section is for quick reference only.




üö® Lessons Learned

IMPORTANT: Focus on recurring issues and patterns that could affect future work. Do not document one-off issues or project-specific details. Prioritize documentation of systemic challenges that could repeat.

üí° Python Environment Issues:
- When running Python scripts on Windows, use `py` instead of `python`
- On PowerShell, use semicolons (`;`) for command separation instead of ampersands (`&&`)
- When navigating directories, be aware of your current location - use `cd ..` to go up a directory

üí° Web Search Implementation:
- Use proper HTTP headers including User-Agent to avoid request blocks
- Include robust retry logic for network failures
- Implement fallbacks for zero-result queries (try simplifying or reformulating)
- Never return unrelated results when no match is found
- Return None/null from internal functions rather than arbitrary defaults

üí° Web Scraping Best Practices:
- Rotate user agents to avoid detection and blocking
- Add random delays between requests to respect server load
- Implement exponential backoff for retry attempts
- Use different extraction strategies for different content types
- Always handle errors gracefully and provide meaningful feedback
- Parse tables carefully, accounting for different HTML structures
- Use CSS selectors for precise content targeting
- Include fallback extraction methods when primary selectors fail

üí° Testing and Packaging:
- Include proper dependencies in requirements.txt (with version numbers)
- Mock external APIs/services for tests to avoid network dependencies
- Use try/except blocks to handle network failures gracefully

üë§ User-Specific Preferences:
- Windows 11 environment with PowerShell as the terminal
- Prefers flat folder structure for utilities in the utils/ folder

üí° Documentation Best Practices:
- Maintain README.md in each module folder for detailed documentation
- Use .cursorrules for recurring patterns, lessons, and quick reference
- Document the "why" behind implementation decisions
- Keep documentation close to the code it describes




üìù Scratchpad

Use actively for immediate thoughts, quick experiments, hypotheses, and exploration. Regularly transfer valuable insights into "Lessons Learned" or "Tools Documentation." Clear regularly.




‚ùì Knowledge Gaps & Questions

Explicitly document knowledge gaps or open questions that need further investigation:

- What additional utilities will be needed in the future?
- Should utilities share common configuration or be completely independent?




üîç Testing & Validation

All tasks must successfully pass appropriate tests before marking the task as completed. Ensure validation clearly confirms task success.

Testing Strategies:
- Create separate test file for each utility module
- Test both success paths and failure paths (including retries)
- Verify CLI tools with both valid and invalid command-line arguments




üîÑ Continuous Improvement Goals

Regularly:
[X] Assess documentation and process effectiveness
[ ] Identify repetitive tasks/inefficiencies for automation
[ ] Proactively challenge assumptions
[ ] Set periodic reviews (weekly/monthly)




üìö Documentation Guidelines

- Focus on concise, actionable information over comprehensive documentation
- Document the "why" behind decisions, not just the "what" and "how"
- Use bullet points and short examples rather than long paragraphs
- Prioritize documenting edge cases, gotchas, and non-obvious behaviors
- Archive older or less relevant documentation when updating
- For .cursorrules:
  * Document only recurring issues and general patterns, not one-off problems
  * Focus on insights that prevent future errors
  * Limit examples to 3-5 lines of code when possible
  * Regularly review and prune outdated information
  * Group similar issues together under clear headings
- For README.md:
  * Focus on clear usage examples
  * Include minimum required parameters
  * Document return values and exceptions
  * Keep API documentation up-to-date with code changes




Regularly revisit this document to summarize insights, prune unnecessary content, and preserve critical instructions clearly.